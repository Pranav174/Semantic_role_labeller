{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentences = []\n",
    "with open(\"processed_data.dat\", \"rb\") as f:\n",
    "    Sentences = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['is_argument', 'arg_class', 'd_rel', 'phrase_type']\n",
    "dt = pd.DataFrame(columns = attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6796/6796 [00:00<00:00, 45598.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_argument</th>\n",
       "      <th>arg_class</th>\n",
       "      <th>d_rel</th>\n",
       "      <th>phrase_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r6</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k1</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k7</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root</td>\n",
       "      <td>VGF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k2</td>\n",
       "      <td>CCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101561</th>\n",
       "      <td>True</td>\n",
       "      <td>ARG2-LOC</td>\n",
       "      <td>k7p</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101562</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101563</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r6</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101564</th>\n",
       "      <td>True</td>\n",
       "      <td>ARG1</td>\n",
       "      <td>k2</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101565</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root</td>\n",
       "      <td>VGF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101566 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_argument arg_class d_rel phrase_type\n",
       "0            False       NaN    r6          NP\n",
       "1            False       NaN    k1          NP\n",
       "2            False       NaN    k7          NP\n",
       "3            False       NaN  root         VGF\n",
       "4            False       NaN    k2         CCP\n",
       "...            ...       ...   ...         ...\n",
       "101561        True  ARG2-LOC   k7p          NP\n",
       "101562       False       NaN  nmod          NP\n",
       "101563       False       NaN    r6          NP\n",
       "101564        True      ARG1    k2          NP\n",
       "101565       False       NaN  root         VGF\n",
       "\n",
       "[101566 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = {\n",
    "    'is_argument' : [],\n",
    "    'arg_class' : [],\n",
    "    'd_rel' : [],\n",
    "    'phrase_type' : [],\n",
    "}\n",
    "for sentence in tqdm(Sentences):\n",
    "    for chunk in sentence.nodeList:\n",
    "#         print(chunk.__dict__)\n",
    "#         data_entry = dict()\n",
    "        if chunk.parentPB != '0':\n",
    "            all_data['is_argument'].append(True)\n",
    "            all_data['arg_class'].append(chunk.parentPBRelation)\n",
    "        else:\n",
    "            all_data['is_argument'].append(False)\n",
    "            all_data['arg_class'].append(np.NaN)\n",
    "        all_data['d_rel'].append(chunk.parentRelation)\n",
    "        all_data['phrase_type'].append(chunk.type)\n",
    "#         print(data_entry)\n",
    "dt = dt.append(pd.DataFrame(all_data))\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argument Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (81252, 2) (81252, 1)\n",
      "Test (20314, 2) (20314, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = dt.values\n",
    "X = dataset[:, 2:]\n",
    "y = dataset[:,0]\n",
    "X = X.astype(str)\n",
    "y = y.reshape((len(y), 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (81252, 88) (81252,)\n",
      "Test (20314, 88) (20314,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pranav_pro/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# prepare input data\n",
    "def prepare_inputs(X,X_train, X_test):\n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(X)\n",
    "    X_train_enc = ohe.transform(X_train)\n",
    "    X_test_enc = ohe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc\n",
    "\n",
    "X_train_enc, X_test_enc = prepare_inputs(X,X_train, X_test)\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "print('Train', X_train_enc.shape, y_train_enc.shape)\n",
    "print('Test', X_test_enc.shape, y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 6s - loss: 0.4156 - accuracy: 0.7688\n",
      "Epoch 2/20\n",
      " - 6s - loss: 0.3990 - accuracy: 0.7791\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.3986 - accuracy: 0.7795\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.3984 - accuracy: 0.7793\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.3981 - accuracy: 0.7799\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.3979 - accuracy: 0.7799\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.3979 - accuracy: 0.7797\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.3979 - accuracy: 0.7798\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.3977 - accuracy: 0.7800\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.3977 - accuracy: 0.7795\n",
      "Epoch 11/20\n",
      " - 6s - loss: 0.3978 - accuracy: 0.7795\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.3976 - accuracy: 0.7797\n",
      "Epoch 13/20\n",
      " - 6s - loss: 0.3976 - accuracy: 0.7801\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.3976 - accuracy: 0.7800\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.3976 - accuracy: 0.7799\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.3976 - accuracy: 0.7796\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.3975 - accuracy: 0.7800\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.3974 - accuracy: 0.7798\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.3975 - accuracy: 0.7804\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.3975 - accuracy: 0.7800\n",
      "Accuracy: 77.50\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential() \n",
    "# model.add(Dense(2, input_dim=input_dim, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train_enc.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_enc, y_train_enc, epochs=20, batch_size=16, verbose=2)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Role Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (26360, 2) (26360, 1)\n",
      "Test (6591, 2) (6591, 1)\n"
     ]
    }
   ],
   "source": [
    "dt_arguments =  dt[dt['arg_class'].notnull()]\n",
    "dataset = dt_arguments.values\n",
    "X = dataset[:, 2:]\n",
    "y = dataset[:,1]\n",
    "X = X.astype(str)\n",
    "y = y.reshape((len(y), 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (26360, 70) (26360, 22)\n",
      "Test (6591, 70) (6591, 22)\n"
     ]
    }
   ],
   "source": [
    "X_train_enc, X_test_enc = prepare_inputs(X,X_train, X_test)\n",
    "y_train_enc, y_test_enc = prepare_inputs(y,y_train, y_test)\n",
    "print('Train', X_train_enc.shape, y_train_enc.shape)\n",
    "print('Test', X_test_enc.shape, y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 3s - loss: 1.2799 - accuracy: 0.6662\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.6636 - accuracy: 0.8138\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.6115 - accuracy: 0.8223\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.5907 - accuracy: 0.8247\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.5809 - accuracy: 0.8258\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.5749 - accuracy: 0.8271\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.5709 - accuracy: 0.8269\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.5678 - accuracy: 0.8269\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.5649 - accuracy: 0.8273\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.5632 - accuracy: 0.8277\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.5620 - accuracy: 0.8274\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.5606 - accuracy: 0.8270\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.5593 - accuracy: 0.8278\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.5580 - accuracy: 0.8275\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.5572 - accuracy: 0.8278\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.5565 - accuracy: 0.8277\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.5561 - accuracy: 0.8274\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.5550 - accuracy: 0.8279\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.5548 - accuracy: 0.8281\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.5543 - accuracy: 0.8276\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.5536 - accuracy: 0.8280\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.5532 - accuracy: 0.8277\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.5527 - accuracy: 0.8278\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.5524 - accuracy: 0.8286\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.5520 - accuracy: 0.8278\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.5514 - accuracy: 0.8280\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.5518 - accuracy: 0.8271\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.5509 - accuracy: 0.8285\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.5508 - accuracy: 0.8291\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.5508 - accuracy: 0.8282\n",
      "Accuracy: 83.17\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(10, input_dim=X_train_enc.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
    "model2.add(Dense(y_train_enc.shape[1], activation='softmax'))\n",
    "# compile the keras model\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model2.fit(X_train_enc, y_train_enc, epochs=30, batch_size=16, verbose=2)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model2.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_models\n",
    "model.save('saved_models/identification_model')\n",
    "model2.save('saved_models/classification_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "ec59e747-00d9-4ab2-a3f2-96cbddf6899a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
