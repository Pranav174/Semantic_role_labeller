{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentences = []\n",
    "with open(\"processed_data.dat\", \"rb\") as f:\n",
    "    Sentences = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['is_argument', 'arg_class', 'd_rel', 'phrase_type', 'predicate_pos']\n",
    "dt = pd.DataFrame(columns = attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6796/6796 [00:00<00:00, 37985.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_argument</th>\n",
       "      <th>arg_class</th>\n",
       "      <th>d_rel</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>predicate_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ccof</td>\n",
       "      <td>NP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>ARG0-GOL</td>\n",
       "      <td>k4a</td>\n",
       "      <td>CCP</td>\n",
       "      <td>VGF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>NP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ccof</td>\n",
       "      <td>NP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>ARGM-TMP</td>\n",
       "      <td>k7t</td>\n",
       "      <td>NP</td>\n",
       "      <td>VGF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101561</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pof</td>\n",
       "      <td>JJP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101562</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r6</td>\n",
       "      <td>VGNN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101563</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ccof</td>\n",
       "      <td>NP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101564</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k1s</td>\n",
       "      <td>JJP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101565</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ccof</td>\n",
       "      <td>VGF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101566 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_argument arg_class d_rel phrase_type predicate_pos\n",
       "0            False       NaN  ccof          NP             0\n",
       "1             True  ARG0-GOL   k4a         CCP           VGF\n",
       "2            False       NaN  nmod          NP             0\n",
       "3            False       NaN  ccof          NP             0\n",
       "4             True  ARGM-TMP   k7t          NP           VGF\n",
       "...            ...       ...   ...         ...           ...\n",
       "101561       False       NaN   pof         JJP             0\n",
       "101562       False       NaN    r6        VGNN             0\n",
       "101563       False       NaN  ccof          NP             0\n",
       "101564       False       NaN   k1s         JJP             0\n",
       "101565       False       NaN  ccof         VGF             0\n",
       "\n",
       "[101566 rows x 5 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = {\n",
    "    'is_argument' : [],\n",
    "    'arg_class' : [],\n",
    "    'd_rel' : [],\n",
    "    'phrase_type' : [],\n",
    "    'predicate_pos' : []\n",
    "}\n",
    "for sentence in tqdm(Sentences):\n",
    "    for chunk in sentence.nodeList:\n",
    "#         print(chunk.__dict__)\n",
    "#         data_entry = dict()\n",
    "        if chunk.parentPB != '0':\n",
    "            all_data['is_argument'].append(True)\n",
    "            all_data['arg_class'].append(chunk.parentPBRelation)\n",
    "        else:\n",
    "            all_data['is_argument'].append(False)\n",
    "            all_data['arg_class'].append(np.NaN)\n",
    "        all_data['d_rel'].append(chunk.parentRelation)\n",
    "        all_data['phrase_type'].append(chunk.type)\n",
    "        all_data['predicate_pos'].append(chunk.parentPB)\n",
    "#         print(data_entry)\n",
    "dt = dt.append(pd.DataFrame(all_data))\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argument Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (81252, 2) (81252, 1)\n",
      "Test (20314, 2) (20314, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = dt.values\n",
    "X = dataset[:, 2:-1]\n",
    "y = dataset[:,0]\n",
    "X = X.astype(str)\n",
    "y = y.reshape((len(y), 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (81252, 88) (81252,)\n",
      "Test (20314, 88) (20314,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshatcx/.virtualenvs/nlp/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/akshatcx/.virtualenvs/nlp/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# prepare input data\n",
    "def prepare_inputs(X,X_train, X_test):\n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(X)\n",
    "    X_train_enc = ohe.transform(X_train)\n",
    "    X_test_enc = ohe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc\n",
    "\n",
    "X_train_enc, X_test_enc = prepare_inputs(X,X_train, X_test)\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "print('Train', X_train_enc.shape, y_train_enc.shape)\n",
    "print('Test', X_test_enc.shape, y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 6s - loss: 0.4203 - accuracy: 0.7652\n",
      "Epoch 2/15\n",
      " - 5s - loss: 0.3992 - accuracy: 0.7784\n",
      "Epoch 3/15\n",
      " - 5s - loss: 0.3989 - accuracy: 0.7784\n",
      "Epoch 4/15\n",
      " - 5s - loss: 0.3985 - accuracy: 0.7789\n",
      "Epoch 5/15\n",
      " - 5s - loss: 0.3984 - accuracy: 0.7791\n",
      "Epoch 6/15\n",
      " - 5s - loss: 0.3985 - accuracy: 0.7793\n",
      "Epoch 7/15\n",
      " - 5s - loss: 0.3982 - accuracy: 0.7792\n",
      "Epoch 8/15\n",
      " - 5s - loss: 0.3981 - accuracy: 0.7796\n",
      "Epoch 9/15\n",
      " - 5s - loss: 0.3980 - accuracy: 0.7794\n",
      "Epoch 10/15\n",
      " - 5s - loss: 0.3979 - accuracy: 0.7795\n",
      "Epoch 11/15\n",
      " - 5s - loss: 0.3980 - accuracy: 0.7794\n",
      "Epoch 12/15\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential() \n",
    "# model.add(Dense(2, input_dim=input_dim, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train_enc.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_enc, y_train_enc, epochs=15, batch_size=16, verbose=2)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Role Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_arguments =  dt[dt['arg_class'].notnull()]\n",
    "dataset = dt_arguments.values\n",
    "X = dataset[:, 2:]\n",
    "y = dataset[:,1]\n",
    "X = X.astype(str)\n",
    "y = y.reshape((len(y), 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc, X_test_enc = prepare_inputs(X,X_train, X_test)\n",
    "y_train_enc, y_test_enc = prepare_inputs(y,y_train, y_test)\n",
    "print('Train', X_train_enc.shape, y_train_enc.shape)\n",
    "print('Test', X_test_enc.shape, y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(10, input_dim=X_train_enc.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
    "model2.add(Dense(y_train_enc.shape[1], activation='softmax'))\n",
    "# compile the keras model\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', recall_m, f1_m, precision_m])\n",
    "# fit the keras model on the dataset\n",
    "model2.fit(X_train_enc, y_train_enc, epochs=20, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "y_pred_enc = model2.predict_classes(X_test_enc)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_test_a = le.transform(y_test)\n",
    "labels = le.inverse_transform([i for i in range(21)])\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=y_test_a, predictions=y_pred_enc).numpy()\n",
    "\n",
    "plt.subplots(figsize=(20,15))\n",
    "sns.set()\n",
    "confusion_matrix = sns.heatmap(con_mat, annot=True, xticklabels=labels, yticklabels=labels, fmt='g')\n",
    "print(\"Confusion Matrix:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, recall, f1_score, precision = model2.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
    "print(\"Scores:\")\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-score: {f1_score}\\nLoss: {loss}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_models\n",
    "model.save('saved_models/identification_model')\n",
    "model2.save('saved_models/classification_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
